{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./../')\n",
    "from pointcloud import PointCloud, load_ply_as_points, point_cloud_numpy_to_object, visualize_point_cloud_object, op3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def visualize_registration(source:op3.PointCloud(), target:op3.PointCloud(), transformation=np.eye(4)):\n",
    "    \"\"\"\n",
    "    Visualize the matching performance of source on target through transformation\n",
    "    Default transformation is I(it means no transform)\n",
    "    :param num_samples: an integer, that is the number of points you want to sample\n",
    "    :return: a point as an array(each element in array is x, y, z, ...)\n",
    "    \"\"\"\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0, 0]) # source point cloud: red\n",
    "    target_temp.paint_uniform_color([0, 0, 1]) # target point cloud: blue\n",
    "    source_temp.transform(transformation)\n",
    "    visualize_point_cloud_object(source_temp, target_temp)\n",
    "    \n",
    "def sample_point_cloud_feature(point_cloud:op3.PointCloud(), voxel_size, verbose=False):\n",
    "    \"\"\"\n",
    "    Down sample and sample the point cloud feature\n",
    "    :param point_cloud: an object of Open3D\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: 2 objects of Open3D, that are down-sampled point cloud and point cloud feature fpfh\n",
    "    \"\"\"\n",
    "    if verbose: print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    point_cloud_down_sample = op3.voxel_down_sample(point_cloud, voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    if verbose: print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    op3.estimate_normals(point_cloud_down_sample, op3.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    if verbose: print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    point_cloud_fpfh = op3.compute_fpfh_feature(point_cloud_down_sample, op3.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return point_cloud_down_sample, point_cloud_fpfh\n",
    "\n",
    "def execute_global_registration(source_down:op3.PointCloud(), target_down:op3.PointCloud(), \n",
    "                                source_fpfh:op3.PointCloud(), target_fpfh:op3.PointCloud(), \n",
    "                                voxel_size, verbose=False):\n",
    "    \"\"\"\n",
    "    Do global matching, find gross transformation form source to target\n",
    "    :param source_down, target_down: 2 objects of Open3D, that are point clouds of source and target after down-sampling\n",
    "    :param source_fpfh, target_fpfh: 2 objects of Open3D, that are point cloud features of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    if verbose:\n",
    "        print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "        print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "        print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = op3.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh,\n",
    "            distance_threshold,\n",
    "            op3.TransformationEstimationPointToPoint(False), 4,\n",
    "            [op3.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            op3.CorrespondenceCheckerBasedOnDistance(distance_threshold)],\n",
    "            op3.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def refine_registration(source:op3.PointCloud(), target:op3.PointCloud(), voxel_size, gross_matching, verbose=False):\n",
    "    \"\"\"\n",
    "    Refine the matching\n",
    "    :param source, target: 2 objects of Open3D, that are point clouds of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param gross_matching: a transformation matrix, that grossly matches source to target\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1\n",
    "    if verbose:\n",
    "        print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "        print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "        print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = op3.registration_icp(source, target, distance_threshold,\n",
    "                                  gross_matching.transformation,\n",
    "                                  op3.TransformationEstimationPointToPlane(),\n",
    "                                  op3.ICPConvergenceCriteria(max_iteration=2000))\n",
    "    return result\n",
    "\n",
    "def match_surface(source:op3.PointCloud(), target:op3.PointCloud(), voxel_size = 0.005, verbose=False):\n",
    "    \"\"\"\n",
    "    Find registertration to transform source point cloud to target point cloud\n",
    "    :param source, target: 2 objects of Open3D, that are point clouds of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    if verbose: visualize_registration(source=source, target=target, transformation=np.identity(4))  # visualize point cloud\n",
    "    \n",
    "    # downsample data\n",
    "    source_down, source_fpfh = sample_point_cloud_feature(point_cloud=source, voxel_size=voxel_size, verbose=verbose)\n",
    "    target_down, target_fpfh = sample_point_cloud_feature(point_cloud=target, voxel_size=voxel_size, verbose=verbose)\n",
    "\n",
    "    # 1st: gross matching(RANSAC)\n",
    "    result_ransac = execute_global_registration(source_down=source_down, target_down=target_down, \n",
    "                                                source_fpfh=source_fpfh, target_fpfh=target_fpfh, \n",
    "                                                voxel_size=voxel_size, verbose=verbose)\n",
    "    if verbose: visualize_registration(source=source_down, target=target_down, transformation=result_ransac.transformation)\n",
    "\n",
    "    # 2nd: fine-tune matching(ICP)\n",
    "    result_icp = refine_registration(source=source_down, target=target_down, voxel_size=voxel_size, gross_matching=result_ransac)\n",
    "    if verbose: visualize_registration(source=source_down, target=target_down, transformation=result_icp.transformation)\n",
    "    return result_icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Checks if a matrix is a valid rotation matrix.\n",
    "def isRotationMatrix(R):\n",
    "    \"\"\"\n",
    "    Check???\n",
    "    :param R: a matrix\n",
    "    :return: a boolean, ???\n",
    "    \"\"\"\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "    \"\"\"\n",
    "    Measure rotations around x, y and z from transformation matrix\n",
    "    :param R: a rotation matrix\n",
    "    :return: an array of 3 values that describe rotations around x, y and z axis, unit is \"radian\"\n",
    "    \"\"\"\n",
    "    assert (isRotationMatrix(R))\n",
    "\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate how to use surface matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_point_cloud1 = './../../data/72_scenes_of_pipe/pipe/1001.ply'\n",
    "path_point_cloud2 = './../../data/72_scenes_of_pipe/pipe/1002.ply'\n",
    "path_point_cloud3 = './../../data/72_scenes_of_pipe/pipe/1003.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "point_cloud1 = PointCloud(points=load_ply_as_points(file_path=path_point_cloud1))\n",
    "point_cloud2 = PointCloud(points=load_ply_as_points(file_path=path_point_cloud2))\n",
    "point_cloud3 = PointCloud(points=load_ply_as_points(file_path=path_point_cloud3))\n",
    "# point_cloud.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_point_cloud_object(point_cloud1.to_object(), point_cloud2.to_object(), point_cloud3.to_object())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should adjust z axis to have better matching result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud1.set_attributes(points=point_cloud1.points-np.array([0, 0, 0.850]))\n",
    "point_cloud2.set_attributes(points=point_cloud2.points-np.array([0, 0, 0.850]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should adjust model to centroid to have better matching result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud1.set_attributes(points=point_cloud1.points-point_cloud1.measure_centroid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matching transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.005.\n",
      ":: Estimate normal with search radius 0.010.\n",
      ":: Compute FPFH feature with search radius 0.025.\n",
      ":: Downsample with a voxel size 0.005.\n",
      ":: Estimate normal with search radius 0.010.\n",
      ":: Compute FPFH feature with search radius 0.025.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.005,\n",
      "   we use a liberal distance threshold 0.007.\n",
      "RegistrationResult with fitness = 0.893805, inlier_rmse = 0.002439, and correspondence_set size of 202\n",
      "Access transformation to get result.\n",
      "Theta x, Theta y, Theta z(in Degree): \n",
      " [-0.38883308  1.03768762 -0.19928092]\n",
      "Translation(in miliMeters): \n",
      " [49.75621156 -1.33373222  1.69698062]\n"
     ]
    }
   ],
   "source": [
    "xtrans = match_surface(source=point_cloud1.to_object(), target=point_cloud2.to_object(), voxel_size=0.005, verbose=True)\n",
    "print(xtrans)\n",
    "print('Theta x, Theta y, Theta z(in Degree): \\n {}'.format(rotationMatrixToEulerAngles(xtrans.transformation[:3, :3]) / np.pi * 180))\n",
    "print('Translation(in miliMeters): \\n {}'.format(xtrans.transformation[:3, 3]*1000 - point_cloud1.centroid*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras] *",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
