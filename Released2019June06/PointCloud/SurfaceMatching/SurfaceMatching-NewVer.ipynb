{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./../..')\n",
    "from PointCloudUtils import op3, load_ply_as_pc, visualize_pc, measure_pc_centroid, adjust_pc_coords, radian2degree, m2mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Checks if a matrix is a valid rotation matrix.\n",
    "def is_rotation_matrix(R: np.array) -> bool:\n",
    "    \"\"\"\n",
    "    Check???\n",
    "    :param R: a matrix of 4x4\n",
    "    :return: a boolean, ???\n",
    "    \"\"\"\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    \"\"\"\n",
    "    Measure rotations around x, y and z from transformation matrix\n",
    "    :param R: a rotation matrix\n",
    "    :return: an array of 3 values that describe rotations around x, y and z axis, unit is \"radian\"\n",
    "    \"\"\"\n",
    "    assert (is_rotation_matrix(R))\n",
    "\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down: op3.PointCloud, target_down: op3.PointCloud, \n",
    "                                source_fpfh: op3.PointCloud, target_fpfh: op3.PointCloud, \n",
    "                                voxel_size: float, verbose=False):\n",
    "    \"\"\"\n",
    "    Do global matching, find gross transformation form source to target\n",
    "    :param source_down, target_down: 2 objects of Open3D, that are point clouds of source and target after down-sampling\n",
    "    :param source_fpfh, target_fpfh: 2 objects of Open3D, that are point cloud features of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    if verbose:\n",
    "        print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "        print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "        print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = op3.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh,\n",
    "            distance_threshold,\n",
    "            op3.TransformationEstimationPointToPoint(False), 4,\n",
    "            [op3.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            op3.CorrespondenceCheckerBasedOnDistance(distance_threshold)],\n",
    "            op3.RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_fast_global_registration(source_down: op3.PointCloud, target_down: op3.PointCloud, \n",
    "                                     source_fpfh: op3.PointCloud, target_fpfh: op3.PointCloud, \n",
    "                                     voxel_size: float, verbose=False):\n",
    "    \"\"\"\n",
    "    Find registertration to transform source point cloud to target point cloud\n",
    "    :param source, target: 2 objects of Open3D, that are point clouds of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    if verbose: \n",
    "        print(\":: Apply fast global registration with distance threshold %.3f\" % distance_threshold)\n",
    "    result = op3.registration_fast_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, \n",
    "        op3.FastGlobalRegistrationOption(maximum_correspondence_distance = distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PointCloudUtils import sample_point_cloud_feature, refine_registration, visualize_registration\n",
    "def global_icp(source: op3.PointCloud, target: op3.PointCloud, voxel_size = 0.005, verbose=False):\n",
    "    \"\"\"\n",
    "    Find registertration to transform source point cloud to target point cloud\n",
    "    :param source, target: 2 objects of Open3D, that are point clouds of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    if verbose: visualize_registration(source=source, target=target, transformation=np.identity(4))  # visualize point cloud\n",
    "    \n",
    "    # downsample data\n",
    "    source_down, source_fpfh = sample_point_cloud_feature(point_cloud=source, voxel_size=voxel_size, verbose=verbose)\n",
    "    target_down, target_fpfh = sample_point_cloud_feature(point_cloud=target, voxel_size=voxel_size, verbose=verbose)\n",
    "\n",
    "    # 1st: gross matching(RANSAC)\n",
    "    result_ransac = execute_global_registration(source_down=source_down, target_down=target_down, \n",
    "                                                source_fpfh=source_fpfh, target_fpfh=target_fpfh, \n",
    "                                                voxel_size=voxel_size, verbose=verbose)\n",
    "    if verbose: visualize_registration(source=source_down, target=target_down, transformation=result_ransac.transformation)\n",
    "\n",
    "    # 2nd: fine-tune matching(ICP)\n",
    "    result_icp = refine_registration(source=source_down, target=target_down, voxel_size=voxel_size, gross_matching=result_ransac)\n",
    "    if verbose: visualize_registration(source=source_down, target=target_down, transformation=result_icp.transformation)\n",
    "    return result_icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_global_icp(source: op3.PointCloud, target: op3.PointCloud, voxel_size = 0.005, verbose=False):\n",
    "    \"\"\"\n",
    "    Find registertration to transform source point cloud to target point cloud\n",
    "    :param source, target: 2 objects of Open3D, that are point clouds of source and target\n",
    "    :param voxel_size: a float value, that is how sparse you want the sample points is\n",
    "    :param verbose: a boolean value, display notification and visualization when True and no notification when False\n",
    "    :return: a transformation object\n",
    "    \"\"\"\n",
    "    if verbose: visualize_registration(source=source, target=target, transformation=np.identity(4))  # visualize point cloud\n",
    "    \n",
    "    # downsample data\n",
    "    source_down, source_fpfh = sample_point_cloud_feature(point_cloud=source, voxel_size=voxel_size, verbose=verbose)\n",
    "    target_down, target_fpfh = sample_point_cloud_feature(point_cloud=target, voxel_size=voxel_size, verbose=verbose)\n",
    "\n",
    "    # 1st: gross matching(RANSAC)\n",
    "    result_ransac = execute_fast_global_registration(source_down=source_down, target_down=target_down, \n",
    "                                                source_fpfh=source_fpfh, target_fpfh=target_fpfh, \n",
    "                                                voxel_size=voxel_size, verbose=verbose)\n",
    "    if verbose: visualize_registration(source=source_down, target=target_down, transformation=result_ransac.transformation)\n",
    "\n",
    "    # 2nd: fine-tune matching(ICP)\n",
    "    result_icp = refine_registration(source=source_down, target=target_down, voxel_size=voxel_size, gross_matching=result_ransac)\n",
    "    if verbose: visualize_registration(source=source_down, target=target_down, transformation=result_icp.transformation)\n",
    "    return result_icp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate how to use surface matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_point_cloud1 = './../../data/72_scenes_of_pipe/pipe/1001.ply'\n",
    "path_point_cloud2 = './../../data/72_scenes_of_pipe/pipe/1002.ply'\n",
    "path_point_cloud3 = './../../data/72_scenes_of_pipe/pipe/1003.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "point_cloud1 = load_ply_as_pc(file_path=path_point_cloud1)\n",
    "point_cloud2 = load_ply_as_pc(file_path=path_point_cloud2)\n",
    "point_cloud3 = load_ply_as_pc(file_path=path_point_cloud3)\n",
    "# point_cloud.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pc(point_cloud1, point_cloud2, point_cloud3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should adjust z axis to have better matching result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud1 = adjust_pc_coords(point_cloud=point_cloud1, coord=[0, 0, 0.850])\n",
    "point_cloud2 = adjust_pc_coords(point_cloud=point_cloud2, coord=[0, 0, 0.850])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should adjust model to centroid to have better matching result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07636259 -0.07773111  0.01330988  0.83884553  0.86357271  0.89967349]\n"
     ]
    }
   ],
   "source": [
    "centroid1 = measure_pc_centroid(point_cloud=point_cloud1); print(centroid1)\n",
    "point_cloud1 = adjust_pc_coords(point_cloud=point_cloud1, coord=centroid1[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matching transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.002.\n",
      ":: Estimate normal with search radius 0.004.\n",
      ":: Compute FPFH feature with search radius 0.010.\n",
      ":: Downsample with a voxel size 0.002.\n",
      ":: Estimate normal with search radius 0.004.\n",
      ":: Compute FPFH feature with search radius 0.010.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.002,\n",
      "   we use a liberal distance threshold 0.003.\n",
      "registration::RegistrationResult with fitness = 0.120092, inlier_rmse = 0.000578, and correspondence_set size of 104\n",
      "Access transformation to get result.\n",
      "Theta x, Theta y, Theta z(in Degree): \n",
      " [-0.88849678  3.00138422 -7.37927514]\n",
      "Translation(in miliMeters): \n",
      " [48.73127258 -3.35798609  0.75714762]\n"
     ]
    }
   ],
   "source": [
    "xtrans = global_icp(source=point_cloud1, target=point_cloud2, voxel_size=0.002, verbose=True)\n",
    "print(xtrans)\n",
    "print('Theta x, Theta y, Theta z(in Degree): \\n {}'.format(radian2degree(rotation_matrix_to_euler_angles(xtrans.transformation[:3, :3]))))\n",
    "print('Translation(in miliMeters): \\n {}'.format(m2mm(xtrans.transformation[:3, 3]) - m2mm(centroid1[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.005.\n",
      ":: Estimate normal with search radius 0.010.\n",
      ":: Compute FPFH feature with search radius 0.025.\n",
      ":: Downsample with a voxel size 0.005.\n",
      ":: Estimate normal with search radius 0.010.\n",
      ":: Compute FPFH feature with search radius 0.025.\n",
      ":: Apply fast global registration with distance threshold 0.003\n",
      "RegistrationResult with fitness = 0.318584, inlier_rmse = 0.001486, and correspondence_set size of 72\n",
      "Access transformation to get result.\n",
      "Theta x, Theta y, Theta z(in Degree): \n",
      " [0.70988453 3.58042679 3.73361342]\n",
      "Translation(in miliMeters): \n",
      " [47.55943785 -0.35614765  1.74757792]\n"
     ]
    }
   ],
   "source": [
    "xtrans = fast_global_icp(source=point_cloud1, target=point_cloud2, voxel_size=0.005, verbose=True)\n",
    "print(xtrans)\n",
    "print('Theta x, Theta y, Theta z(in Degree): \\n {}'.format(radian2degree(rotation_matrix_to_euler_angles(xtrans.transformation[:3, :3]))))\n",
    "print('Translation(in miliMeters): \\n {}'.format(m2mm(xtrans.transformation[:3, 3]) - m2mm(centroid1[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 ms ± 36.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtrans = global_icp(source=point_cloud1, target=point_cloud2, voxel_size=0.005, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.9 ms ± 1.28 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtrans = fast_global_icp(source=point_cloud1, target=point_cloud2, voxel_size=0.005, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
